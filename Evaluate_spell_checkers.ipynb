{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate spell checkers"
      ],
      "metadata": {
        "id": "87mb7SJLW_k0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook presents an evaluation of some existing spell checkers on the collected evaluation SpellGram dataset. First, I'll introduce the metrics and spell checkers; then, we'll evaluate them."
      ],
      "metadata": {
        "id": "cQpQRegn2eZO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics for evaluation"
      ],
      "metadata": {
        "id": "hyGBxkL0XJIh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's introduce some steps of spell checking process:\n",
        "\n",
        "1. Decide if a word is misspelled or not\n",
        "2. If we get positive answer from the step 1, one needs to correct that misspelled word to make it correctly spelled\n",
        "\n",
        "Figure below shows the schematic process of automatic spelling correction. **We'll be evaluating the final corrected result rather than detection and then correction separately**. (image source: [Survey of Automatic Spelling Correction](https://www.mdpi.com/2079-9292/9/10/1670))\n",
        "![Automatic Spelling Survey.webp](data:image/webp;base64,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)"
      ],
      "metadata": {
        "id": "vwONoBXQS4x0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The evaluation metrics can be classified as follows:\n",
        "\n",
        "1. Classification metrics of misspelled word correction: either 1 if corrected accurately or 0 otherwise\n",
        "- **Accuracy** (Percentage of words that are corrected accurately)\n",
        "- **Precision** (how many of the words flagged as incorrect were incorrect)\n",
        "- **Recall** (how many of the actual misspelled words were correctly flagged)\n",
        "- **F1-Score** (harmonic mean of precision and recall)\n",
        "\n",
        "Advantage: easy and widely-used.\n",
        "\n",
        "Disadvantage: only the best candidate from the suggestion list is considered.\n",
        "\n",
        "2. Sequence-to-sequence evaluation metrics\n",
        "- **bilingual-evaluation-understudy (BLEU)** (adapted from machine translation)\n",
        "- **Word Error Rate (WER)** (widely used in Automatic Speech Recognition)\n",
        "\n",
        "Advantage: easy and quick to implement.\n",
        "\n",
        "Disadvantage: BLEU can't be calculated on a sentence level, only on a corpus level.\n",
        "\n",
        "3. Information retrieval\n",
        "- **Mean reciprocal rank**\n",
        "- **Mean average precision**\n",
        "\n",
        "Advantage: automatic spelling correction is similar to information retrieval so we can consider n best candidates.\n",
        "\n",
        "Disadvantage: the candidate list must be large enough to contain the correct answer.\n",
        "\n",
        "Sources:\n",
        "1. [Survey of Automatic Spelling Correction](https://www.mdpi.com/2079-9292/9/10/1670)\n",
        "2. [Foundations of NLP Explained — Bleu Score and WER Metrics](https://towardsdatascience.com/foundations-of-nlp-explained-bleu-score-and-wer-metrics-1a5ba06d812b)\n",
        "3. [spell-checkers-comparison](https://github.com/diffitask/spell-checkers-comparison/blob/main/spell-checkers-comparison.ipynb)\n"
      ],
      "metadata": {
        "id": "rfU-7gWrs9Gz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------\n",
        "In our evaluation, we'll use classification metrics to measure the percentage of corrected misspellings because we have quite simple misspellings that occur just once within one word.\n",
        "\n",
        "**We'll calculate Accuracy/Precision/Recall/F1-Score** for each sentence (only considering the misspelled words) and then average them for all evaluation dataset."
      ],
      "metadata": {
        "id": "ODrpR9e03OJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from typing import List, Tuple"
      ],
      "metadata": {
        "id": "yqemX-j4LeQl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(source_sentences: List[str],\n",
        "                    target_sentences: List[str],\n",
        "                    corrected_sentences: List[str]) -> Tuple[float, float, float, float]:\n",
        "    \"\"\"\n",
        "    Compute evaluation metrics given source, target and corrected sentences\n",
        "    \"\"\"\n",
        "\n",
        "    assert len(source_sentences) == len(target_sentences) == len(corrected_sentences), \"Needed to be of the same length!\"\n",
        "\n",
        "    accuracies = []\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    f1_scores = []\n",
        "\n",
        "    for source_sentence, target_sentence, corrected_sentence in zip(source_sentences, target_sentences, corrected_sentences):\n",
        "        source_words = source_sentence.split()\n",
        "        target_words = target_sentence.split()\n",
        "        corrected_words = corrected_sentence.split()\n",
        "\n",
        "        # If sentences have different lengths, you can truncate/pad for alignment\n",
        "        max_len = max(len(source_words), len(target_words), len(corrected_words))\n",
        "        source_words.extend([''] * (max_len - len(source_words)))\n",
        "        target_words.extend([''] * (max_len - len(target_words)))\n",
        "        corrected_words.extend([''] * (max_len - len(corrected_words)))\n",
        "\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "\n",
        "        # Only evaluate for misspelled words\n",
        "        for s_word, t_word, c_word in zip(source_words, target_words, corrected_words):\n",
        "            if s_word != t_word:  # Word was misspelled in source\n",
        "                y_true.append(1)  # \"1\" means the word needed correction\n",
        "                if c_word == t_word:  # Corrected correctly\n",
        "                    y_pred.append(1)  # \"1\" means it was corrected correctly\n",
        "                else:\n",
        "                    y_pred.append(0)  # Incorrect correction or not corrected at all\n",
        "\n",
        "        # If there are misspelled words in the sentence, calculate the metrics\n",
        "        if len(y_true) > 0:\n",
        "            accuracy = accuracy_score(y_true, y_pred)\n",
        "            precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "            recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "            f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "            accuracies.append(accuracy)\n",
        "            precisions.append(precision)\n",
        "            recalls.append(recall)\n",
        "            f1_scores.append(f1)\n",
        "        else:\n",
        "            # If no misspelled words in this sentence, ignore or append zeros\n",
        "            accuracies.append(1.0)  # 100% accuracy for sentences without misspelled words\n",
        "            precisions.append(1.0)\n",
        "            recalls.append(1.0)\n",
        "            f1_scores.append(1.0)\n",
        "\n",
        "    # Calculate average metrics across all sentences\n",
        "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
        "    avg_precision = sum(precisions) / len(precisions)\n",
        "    avg_recall = sum(recalls) / len(recalls)\n",
        "    avg_f1 = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "    return avg_accuracy, avg_precision, avg_recall, avg_f1"
      ],
      "metadata": {
        "id": "ebKkupolKxgD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Existing approach. Pre-trained models and rule-based methods"
      ],
      "metadata": {
        "id": "zZ9iE6vtXLvL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Approach I chose for evaluation:\n",
        "\n",
        "1. [spelling-correction-english-base](https://huggingface.co/oliverguhr/spelling-correction-english-base): Bart-based spell checker which was finetuned for the spelling correction task.\n",
        "2. [Autocorrect](https://github.com/filyp/autocorrect): Spelling corrector in python based on rule-based methods.\n",
        "3. [spellCheck](https://github.com/R1j1t/contextualSpellCheck): non-word error (NWE) correction using pretrained BERT model without finetuning.\n",
        "4. [t5-base-spellchecker](https://huggingface.co/Bhuvana/t5-base-spellchecker): T5 Base-based (most probably) finetuned Spellchecker.\n",
        "\n",
        "I chose this combination because I wanted to test both rule-based methods and pretrained language model-based methods. My guess is that the latter will handle spelling correction better because such models can catch semantics/syntax long dependencies when dealing with sentences.\n",
        "\n",
        "-----------"
      ],
      "metadata": {
        "id": "ocF1FThL398N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other spell checkers worth mentioning which we won't be evaluating here (for different reasons, including that some of them work on a word level or their main mechanism is similar to the ones I've already chosen):\n",
        "\n",
        "- [Spell checker using T5 base transformer](Bhuvana/t5-base-spellchecker): A simple spell checker based on T5-Base transformer model.\n",
        "- [TextBlob](https://textblob.readthedocs.io/en/dev/): is a Python library for processing textual data, spell correction is among other features. Based on the same method as Autocorrect.\n",
        "- [Pyspellchecker](https://pypi.org/project/pyspellchecker/): simple spell checker based on a Levenshtein Distance algorithm to find permutations within an edit distance of 2 from the original word. Works on a word level.\n",
        "\n",
        "Others:\n",
        "- [Grammarly](https://www.grammarly.com/)\n",
        "- [Ginger](https://www.gingersoftware.com/spellcheck)\n",
        "\n",
        "and many more...it would take too much space to describe them all + their underlying mechanism repeat each other.\n"
      ],
      "metadata": {
        "id": "OpGwOA3p4wzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate"
      ],
      "metadata": {
        "id": "Llg5-oo-XSoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's load our evaluation dataset and shuffle it (but keep the source-target connections)"
      ],
      "metadata": {
        "id": "xfVE7C1tFsx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "eval_dataset = pd.read_csv(\"/content/SpellGram_dataset_2k.csv\")\n",
        "eval_dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-ld0f7lCFvxo",
        "outputId": "dfe757a9-640b-42cc-b94c-6a73e011bac3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                       source  \\\n",
              "0           0        rate the silent upeaker four out oe 6   \n",
              "1           1    please find me tqe gork tqe bfrning sorld   \n",
              "2           2  three friendl afe relaxing uround the tsble   \n",
              "3           3                            what dm they want   \n",
              "4           4           man in tan aat working with stones   \n",
              "\n",
              "                                        target  \n",
              "0        rate the silent speaker four out of 6  \n",
              "1    please find me the work the burning world  \n",
              "2  three friends are relaxing around the table  \n",
              "3                            what do they want  \n",
              "4           man in tan hat working with stones  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16fb9716-0abc-4356-b323-f4d18c1194f6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>rate the silent upeaker four out oe 6</td>\n",
              "      <td>rate the silent speaker four out of 6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>please find me tqe gork tqe bfrning sorld</td>\n",
              "      <td>please find me the work the burning world</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>three friendl afe relaxing uround the tsble</td>\n",
              "      <td>three friends are relaxing around the table</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>what dm they want</td>\n",
              "      <td>what do they want</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>man in tan aat working with stones</td>\n",
              "      <td>man in tan hat working with stones</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16fb9716-0abc-4356-b323-f4d18c1194f6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-16fb9716-0abc-4356-b323-f4d18c1194f6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-16fb9716-0abc-4356-b323-f4d18c1194f6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-44823bda-4e35-4eea-840c-3703e831a503\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-44823bda-4e35-4eea-840c-3703e831a503')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-44823bda-4e35-4eea-840c-3703e831a503 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "eval_dataset",
              "summary": "{\n  \"name\": \"eval_dataset\",\n  \"rows\": 2000,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 577,\n        \"min\": 0,\n        \"max\": 1999,\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          1860,\n          353,\n          1333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"the course was officially openxed by his royal highness prince bertil\",\n          \"he iu tse eldest son of noel turnour tse seventh earls youtger brother\",\n          \"she tied er shoelaces into a bow\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"the course was officially opened by his royal highness prince bertil\",\n          \"he is the eldest son of noel turnour the seventh earls younger brother\",\n          \"she tied her shoelaces into a bow\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset = eval_dataset.sample(frac=1)\n",
        "eval_texts = eval_dataset['source'].to_list()\n",
        "target_texts = eval_dataset['target'].to_list()"
      ],
      "metadata": {
        "id": "bQB4aC0KF-OY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Finetuned Bart transformer model"
      ],
      "metadata": {
        "id": "yt4z1XPpEiEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "import string\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "lz4QX9NUFmbt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "n1Fsl3HUKN7r"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fix_spelling = pipeline(\"text2text-generation\",\n",
        "                        model=\"oliverguhr/spelling-correction-english-base\",\n",
        "                        device=device)"
      ],
      "metadata": {
        "id": "Z-2YL__CXUIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bart_predictions = []\n",
        "\n",
        "for text in tqdm(eval_texts):\n",
        "    prediction = fix_spelling(text,max_length=2048)[0]['generated_text']\n",
        "    clean_prediction = prediction.translate(str.maketrans('', '', string.punctuation))\n",
        "    bart_predictions.append(clean_prediction.lower())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AcLUZIdFrGJ",
        "outputId": "2f2b40c4-6314-44cb-f8f2-b8f9d97d6e4d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 10/2000 [00:04<05:50,  5.68it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "100%|██████████| 2000/2000 [04:57<00:00,  6.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate metrics for Bart predictions"
      ],
      "metadata": {
        "id": "qPyn1t8pS4aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_accuracy, avg_precision, avg_recall, avg_f1 = compute_metrics(eval_texts,\n",
        "                                                                  target_texts,\n",
        "                                                                  bart_predictions)\n",
        "\n",
        "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
        "print(f\"Average Precision: {avg_precision:.4f}\")\n",
        "print(f\"Average Recall: {avg_recall:.4f}\")\n",
        "print(f\"Average F1 Score: {avg_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peYPVXmgR70V",
        "outputId": "f591a356-adeb-4918-cd26-8a63c9b7b531"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7670\n",
            "Average Precision: 0.8770\n",
            "Average Recall: 0.7670\n",
            "Average F1 Score: 0.8039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Autocorrect"
      ],
      "metadata": {
        "id": "M2wgyIwPKswq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autocorrect"
      ],
      "metadata": {
        "id": "rMgJuXFoR-b2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autocorrect import Speller"
      ],
      "metadata": {
        "id": "9gL-m_uYTyK0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spell = Speller()"
      ],
      "metadata": {
        "id": "ebgVMDz2T5ND"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autocorrect_predictions = []\n",
        "\n",
        "for text in tqdm(eval_texts):\n",
        "    prediction = spell(text)\n",
        "    autocorrect_predictions.append(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz3EneGiTu4b",
        "outputId": "8d7020c8-360c-406f-e112-9cfc07a3ffd3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [02:00<00:00, 16.56it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_accuracy, avg_precision, avg_recall, avg_f1 = compute_metrics(eval_texts,\n",
        "                                                                  target_texts,\n",
        "                                                                  autocorrect_predictions)\n",
        "\n",
        "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
        "print(f\"Average Precision: {avg_precision:.4f}\")\n",
        "print(f\"Average Recall: {avg_recall:.4f}\")\n",
        "print(f\"Average F1 Score: {avg_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaNA-cnVUDCe",
        "outputId": "a12a3ecc-6def-41c8-e0bc-66e7d52c02c7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.5233\n",
            "Average Precision: 0.7140\n",
            "Average Recall: 0.5233\n",
            "Average F1 Score: 0.5817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. spellCheck"
      ],
      "metadata": {
        "id": "NWrdxxTSR_vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contextualSpellCheck"
      ],
      "metadata": {
        "id": "j2U3Ld47UXqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import contextualSpellCheck\n",
        "import spacy"
      ],
      "metadata": {
        "id": "mYRVdzkbYr0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "contextualSpellCheck.add_to_pipe(nlp)"
      ],
      "metadata": {
        "id": "QKvKAldfY1Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spellcheck_predictions = []\n",
        "\n",
        "for text in tqdm(eval_texts):\n",
        "    doc = nlp(text)\n",
        "    spellcheck_predictions.append(doc._.outcome_spellCheck.lower())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtDJqb0KY4z_",
        "outputId": "781c1e93-b693-4633-de37-22c0bedcf516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [28:02<00:00,  1.19it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_accuracy, avg_precision, avg_recall, avg_f1 = compute_metrics(eval_texts,\n",
        "                                                                  target_texts,\n",
        "                                                                  spellcheck_predictions)\n",
        "\n",
        "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
        "print(f\"Average Precision: {avg_precision:.4f}\")\n",
        "print(f\"Average Recall: {avg_recall:.4f}\")\n",
        "print(f\"Average F1 Score: {avg_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gw7n_YVabbiD",
        "outputId": "33ba8e07-d504-43dd-8c3f-08a42989fed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.3429\n",
            "Average Precision: 0.5165\n",
            "Average Recall: 0.3429\n",
            "Average F1 Score: 0.3916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. T5 Base Spellchecker"
      ],
      "metadata": {
        "id": "gw1X6YjadI5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install accelerate"
      ],
      "metadata": {
        "id": "fO_Xz2tVdPo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch"
      ],
      "metadata": {
        "id": "tD5kRgSNdirH"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "9dnwV3kpdqC_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Bhuvana/t5-base-spellchecker\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Bhuvana/t5-base-spellchecker\", device_map=device)"
      ],
      "metadata": {
        "id": "3NnUYaHgdIfh"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def correct(inputs: str) -> str:\n",
        "    \"\"\"\n",
        "    Predict correctly spelled sentence using pretrained T5 base model\n",
        "    \"\"\"\n",
        "\n",
        "    input_ids = tokenizer.encode(inputs,return_tensors='pt').to(device)\n",
        "    sample_output = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=True,\n",
        "        max_length=5000,\n",
        "        top_p=0.99,\n",
        "        num_return_sequences=1\n",
        "    )\n",
        "    res = tokenizer.decode(sample_output[0], skip_special_tokens=True)\n",
        "    return res"
      ],
      "metadata": {
        "id": "V3JRoLaSdhFw"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t5base_predictions = []\n",
        "\n",
        "for text in tqdm(eval_texts):\n",
        "    t5base_predictions.append(correct(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXXJ4DB6fWjX",
        "outputId": "805df075-26a0-4133-e079-af565f0c52e2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [08:56<00:00,  3.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_accuracy, avg_precision, avg_recall, avg_f1 = compute_metrics(eval_texts,\n",
        "                                                                  target_texts,\n",
        "                                                                  t5base_predictions)\n",
        "\n",
        "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
        "print(f\"Average Precision: {avg_precision:.4f}\")\n",
        "print(f\"Average Recall: {avg_recall:.4f}\")\n",
        "print(f\"Average F1 Score: {avg_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N70o6eFmgHau",
        "outputId": "da66c868-9bc9-44db-aa9f-e984008c5f34"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.3823\n",
            "Average Precision: 0.4985\n",
            "Average Recall: 0.3823\n",
            "Average F1 Score: 0.4179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary"
      ],
      "metadata": {
        "id": "Mv89tjLGXUXg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **General observations**\n",
        "\n",
        "In the table below you can see evaluation results of all 4 approach I used on the evaluation dataset.\n",
        "- As expected, pretrained language model (Bart-based) handled the task most accurately among others, however, another language model (T5-based) showed quite low metrics. The potential reason for that is that while T5 model can be powerful for complex tasks such as machine translation, it could struggle with small-scale corrections (like spelling errors) on a token level.\n",
        "\n",
        "- Moreover, I got surprisingly low results on Bert-based approach (spellCheck) which might be explained by the fact that the base Bert model wasn't finetuned for the spelling correction task (unlike the Bart-based one).\n",
        "\n",
        "- Autocorrect got the second place among other approach which is not that bad considering that it's an algorithm-based approach."
      ],
      "metadata": {
        "id": "e_2nhhkekQu1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Approach | Accuracy | Precision | Recall | F1-Score |\n",
        "|----------|----------|----------|----------|----------|\n",
        "|   **Bart-based model** |   **0.767**  |   **0.877**  | **0.767**  | **0.804** |\n",
        "|   Autocorrect  |   0.523  |   0.714  | 0.523  | 0.582 |\n",
        "|   T5-based model  |   0.382  |   0.499  | 0.382  | 0.418  |\n",
        "|   spellCheck |   0.343  |   0.517  | 0.343  | 0.392  |\n",
        "\n"
      ],
      "metadata": {
        "id": "9QnS-PtsiUeI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Strengths and weaknesses**\n",
        "\n",
        "### 1. Rule-based approach\n",
        "Let's see Autocorrect's mistakes made in spelling correction"
      ],
      "metadata": {
        "id": "1nRpLwrPtwdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for s_sent, t_sent, p_sent in zip(eval_texts[:10], target_texts[:10], autocorrect_predictions[:10]):\n",
        "  for s_word, t_word, p_word in zip(s_sent.split(), t_sent.split(), p_sent.split()):\n",
        "          if s_word != t_word and p_word != t_word:\n",
        "            print(t_sent)\n",
        "            print(\"source word:\", s_word)\n",
        "            print(\"target word:\", t_word)\n",
        "            print(\"predicted word:\", p_word)\n",
        "            print('-'*10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73VEpqhHtsGW",
        "outputId": "dd417fd6-0b49-46c9-c077-32dc4ed62147"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nor did he consider his decision a particularly courageous one\n",
            "source word: she\n",
            "target word: he\n",
            "predicted word: she\n",
            "----------\n",
            "the hail pattered on the burnt brown grass\n",
            "source word: patteled\n",
            "target word: pattered\n",
            "predicted word: battled\n",
            "----------\n",
            "the hail pattered on the burnt brown grass\n",
            "source word: grajj\n",
            "target word: grass\n",
            "predicted word: gray\n",
            "----------\n",
            "your rusty bicycle chain could use some lube\n",
            "source word: rusth\n",
            "target word: rusty\n",
            "predicted word: rush\n",
            "----------\n",
            "two further instances of this name in celtic sources may also be included jes\n",
            "source word: ir\n",
            "target word: in\n",
            "predicted word: ir\n",
            "----------\n",
            "the constant changes of sultans that followed led to great disorder in the provinces\n",
            "source word: yn\n",
            "target word: in\n",
            "predicted word: yn\n",
            "----------\n",
            "the impact of a drought on a society\n",
            "source word: n\n",
            "target word: on\n",
            "predicted word: n\n",
            "----------\n",
            "she will recover from this shock\n",
            "source word: fom\n",
            "target word: from\n",
            "predicted word: fom\n",
            "----------\n",
            "that all sounds a bit of a kerfuffle\n",
            "source word: rhar\n",
            "target word: that\n",
            "predicted word: rear\n",
            "----------\n",
            "that all sounds a bit of a kerfuffle\n",
            "source word: acc\n",
            "target word: all\n",
            "predicted word: acc\n",
            "----------\n",
            "that all sounds a bit of a kerfuffle\n",
            "source word: x\n",
            "target word: a\n",
            "predicted word: x\n",
            "----------\n",
            "that all sounds a bit of a kerfuffle\n",
            "source word: x\n",
            "target word: a\n",
            "predicted word: x\n",
            "----------\n",
            "richards died of a heart attack soon after his arrival\n",
            "source word: heat\n",
            "target word: heart\n",
            "predicted word: heat\n",
            "----------\n",
            "richards died of a heart attack soon after his arrival\n",
            "source word: hi\n",
            "target word: his\n",
            "predicted word: hi\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pros:\n",
        "\n",
        "- Fast, takes up little memory resources\n",
        "\n",
        "Cons:\n",
        "\n",
        "- Misses semantics/syntax\n",
        "- Might have problems with catching real word errors (misspelled string is a valid word in the language)\n",
        "- Might struggle with names/cities/etc.\n",
        "- Might not handle more complex misspellings, it stuggles even with several misspellings within one sentence"
      ],
      "metadata": {
        "id": "3iVuHNzOYepo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Language model-based approach\n",
        "\n",
        "Let's explore Bart-based model's mistakes in spelling correction (I don't take Bert-based and T5-based models because they showed worse results)."
      ],
      "metadata": {
        "id": "ByQHYhFrq3kn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for s_sent, t_sent, p_sent in zip(eval_texts[:10], target_texts[:10], bart_predictions[:10]):\n",
        "  for s_word, t_word, p_word in zip(s_sent.split(), t_sent.split(), p_sent.split()):\n",
        "          if s_word != t_word and p_word != t_word:\n",
        "            print(t_sent)\n",
        "            print(\"source word:\", s_word)\n",
        "            print(\"target word:\", t_word)\n",
        "            print(\"predicted word:\", p_word)\n",
        "            print('-'*10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "224-_E5ErCBI",
        "outputId": "94144e94-5a9d-492d-8fc2-b5db01feb4ef"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nor did he consider his decision a particularly courageous one\n",
            "source word: she\n",
            "target word: he\n",
            "predicted word: she\n",
            "----------\n",
            "the hail pattered on the burnt brown grass\n",
            "source word: patteled\n",
            "target word: pattered\n",
            "predicted word: patteled\n",
            "----------\n",
            "the hail pattered on the burnt brown grass\n",
            "source word: grajj\n",
            "target word: grass\n",
            "predicted word: graj\n",
            "----------\n",
            "your rusty bicycle chain could use some lube\n",
            "source word: rusth\n",
            "target word: rusty\n",
            "predicted word: rust\n",
            "----------\n",
            "that all sounds a bit of a kerfuffle\n",
            "source word: rhar\n",
            "target word: that\n",
            "predicted word: rhar\n",
            "----------\n",
            "that all sounds a bit of a kerfuffle\n",
            "source word: acc\n",
            "target word: all\n",
            "predicted word: acc\n",
            "----------\n",
            "richards died of a heart attack soon after his arrival\n",
            "source word: heat\n",
            "target word: heart\n",
            "predicted word: heat\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pros:\n",
        "- Many incorrectly made corrections are semantically and syntactically appropriate. Moreover, a misspelled word might be ambiguous even for the human to correct (for example, one might correct *fetsts* to *tests* in *they conduct annual technical fests which are attended by students from around the nation*). So, we might say that there mistakes can occur due to the samples ambiguity but not the model itself\n",
        "- High accuracy\n",
        "\n",
        "Cons:\n",
        "- More heavy in terms of memory and speed of processing\n",
        "- Needed to be finetuned\n",
        "- Ranking of candidates should be considered since there can be several potentially good solutions"
      ],
      "metadata": {
        "id": "-vxGx2Khq2M4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion"
      ],
      "metadata": {
        "id": "gZcrDIbBvJc3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall, I see large language models approach as a favorable one for the spelling correction task because they are more robust, able to handle more complex misspellings without losing contextual meaning.\n",
        "\n",
        "For the future research I would search for more data especially for more complex cases (for example, ones of dyslexic adult people or typos made in haste), and also with several misspellings within one word. I believe that the quality of the training dataset will play one the most crucial roles in this task. Then, by carefully finetuning a large Language model one can get a nice spell checker.\n",
        "\n",
        "It's important to consider other evaluation metrics to evaluate not only the first and most plausible candidate for the correction but *n* most suitable ones. One can also explore the words which were not supposed to be changed but they were changed by a model.\n",
        "\n",
        "Moreover, one can add syntactic corrections and better writing practices suggestions."
      ],
      "metadata": {
        "id": "aP-No8SuvLXM"
      }
    }
  ]
}